{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52af0753",
   "metadata": {},
   "source": [
    "# Multi-Agent RAG System for HR Queries\n",
    "## Ravikumar's Personal Data Retrieval System\n",
    "\n",
    "This notebook implements a multi-agent system using Groq API that:\n",
    "1. **Validates** HR-appropriate questions\n",
    "2. **Retrieves** relevant information from Ravi_Total.docx\n",
    "3. **Orchestrates** multi-agent workflows\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f66f6d",
   "metadata": {},
   "source": [
    "## Section 1: Import Required Libraries and Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4350da24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing python-dotenv...\n",
      "Installing langchain...\n",
      "Installing langchain-groq...\n",
      "Installing langchain-community...\n",
      "Installing faiss-cpu...\n",
      "Installing python-docx...\n",
      "Installing pydantic...\n",
      "Installing langchain-text-splitters...\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Install packages\n",
    "packages = [\n",
    "    'python-dotenv',\n",
    "    'langchain',\n",
    "    'langchain-groq',\n",
    "    'langchain-community',\n",
    "    'faiss-cpu',\n",
    "    'python-docx',\n",
    "    'pydantic',\n",
    "    'langchain-text-splitters'\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    print(f\"Installing {package}...\")\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23089ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asdmf\n"
     ]
    }
   ],
   "source": [
    "print(\"asdmf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbbd8917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì GROQ_API_KEY loaded successfully\n",
      "‚úì API Key (first 20 chars): gsk_sRZTINZivrrYo6Jn...\n",
      "‚úì Data folder path: data\n",
      "‚úì Document file: data\\Ravi_Total.docx\n",
      "‚úì File exists: True\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get API key\n",
    "GROQ_API_KEY = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if not GROQ_API_KEY:\n",
    "    raise ValueError(\"GROQ_API_KEY not found in .env file\")\n",
    "\n",
    "print(\"‚úì GROQ_API_KEY loaded successfully\")\n",
    "print(f\"‚úì API Key (first 20 chars): {GROQ_API_KEY[:20]}...\")\n",
    "\n",
    "# Set workspace path\n",
    "WORKSPACE_PATH = Path('.')\n",
    "DATA_FOLDER = WORKSPACE_PATH / 'data'\n",
    "DOCX_FILE = DATA_FOLDER / 'Ravi_Total.docx'\n",
    "\n",
    "print(f\"‚úì Data folder path: {DATA_FOLDER}\")\n",
    "print(f\"‚úì Document file: {DOCX_FILE}\")\n",
    "print(f\"‚úì File exists: {DOCX_FILE.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd58d35",
   "metadata": {},
   "source": [
    "## Section 2: Load and Process Document Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9127f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading document...\n",
      "‚úì Document loaded successfully\n",
      "‚úì Total characters: 24414\n",
      "‚úì Preview (first 500 chars):\n",
      "PERSONAL PROFILE  \n",
      "Name: RAVIKUMAR D  \n",
      "Phone: +91 8825677072  \n",
      "Email: rkumard777@gmail.com  \n",
      "Portfolio: https://ravikumard.netlify.app/  \n",
      "LinkedIn: https://www.linkedin.com/in/ravi-kumar-d-6426ba291  \n",
      "GitHub: https://github.com/ravikumard0748  \n",
      "Competitive Profiles:  \n",
      "- LeetCode: https://leetcode.com/ravikumard/  \n",
      "- CodeChef: https://www.codechef.com/users/ravikumard  \n",
      "- HackerRank: https://www.hackerrank.com/profile/ravikumar_d20231  \n",
      "- HackerEarth: https://www.hackerearth.com/@ravikumar.d2023a\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Load and extract text from DOCX file\n",
    "from docx import Document\n",
    "\n",
    "def load_docx(file_path):\n",
    "    \"\"\"Load and extract text from a Word document\"\"\"\n",
    "    doc = Document(file_path)\n",
    "    full_text = []\n",
    "    \n",
    "    for paragraph in doc.paragraphs:\n",
    "        if paragraph.text.strip():\n",
    "            full_text.append(paragraph.text)\n",
    "    \n",
    "    # Also extract text from tables\n",
    "    for table in doc.tables:\n",
    "        for row in table.rows:\n",
    "            for cell in row.cells:\n",
    "                if cell.text.strip():\n",
    "                    full_text.append(cell.text)\n",
    "    \n",
    "    return \"\\n\".join(full_text)\n",
    "\n",
    "# Load the document\n",
    "print(\"Loading document...\")\n",
    "document_text = load_docx(DOCX_FILE)\n",
    "\n",
    "print(f\"‚úì Document loaded successfully\")\n",
    "print(f\"‚úì Total characters: {len(document_text)}\")\n",
    "print(f\"‚úì Preview (first 500 chars):\\n{document_text[:500]}\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95584cad",
   "metadata": {},
   "source": [
    "## Section 3: Initialize Groq LLM and Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff36951b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dasf\n"
     ]
    }
   ],
   "source": [
    "print(\"dasf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e0410a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model_name=\"llama-3.1-8b-instant\",\n",
    "    temperature=0.3,\n",
    "    max_tokens=256\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92d3ed6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# llm = ChatGroq(\n",
    "#     groq_api_key=GROQ_API_KEY,\n",
    "#     model_name=\"llama-3.1-8b-instant\",\n",
    "#     temperature=0.7,\n",
    "#     max_tokens=2048\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73ca4921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Groq LLM initialized successfully\n",
      "‚úì Model: mixtral-8x7b-32768\n",
      "\n",
      "‚úì LLM Test Response:\n",
      "Nice to meet you. I'm Rohan, Ravikumar's HR assistant. I'll be happy to assist you with any HR-related queries or concerns you may have. How can I help you today?...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"‚úì Groq LLM initialized successfully\")\n",
    "print(f\"‚úì Model: mixtral-8x7b-32768\")\n",
    "\n",
    "# Test the LLM\n",
    "test_message = \"Hello, can you introduce yourself as Ravikumar's HR assistant?\"\n",
    "test_response = llm.invoke(test_message)\n",
    "print(f\"\\n‚úì LLM Test Response:\\n{test_response.content[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16381975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing Embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ravik\\OneDrive\\Desktop\\RABOT\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Embeddings initialized successfully\n",
      "‚úì Model: all-MiniLM-L6-v2\n",
      "‚úì Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "# Initialize embeddings using Groq\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "print(\"\\nInitializing Embeddings...\")\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "print(\"‚úì Embeddings initialized successfully\")\n",
    "print(f\"‚úì Model: all-MiniLM-L6-v2\")\n",
    "\n",
    "# Test embedding\n",
    "test_embedding = embeddings.embed_query(\"Tell me about your experience\")\n",
    "print(f\"‚úì Embedding dimension: {len(test_embedding)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf79669",
   "metadata": {},
   "source": [
    "## Section 4: Build Vector Store from Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57a07706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting document into chunks...\n",
      "‚úì Document split into 65 chunks\n",
      "‚úì Average chunk size: 375 characters\n",
      "\n",
      "First chunk preview:\n",
      "PERSONAL PROFILE  \n",
      "Name: RAVIKUMAR D  \n",
      "Phone: +91 8825677072  \n",
      "Email: rkumard777@gmail.com  \n",
      "Portfolio: https://ravikumard.netlify.app/  \n",
      "LinkedIn: https://www.linkedin.com/in/ravi-kumar-d-6426ba291  \n",
      "GitHub: https://github.com/ravikumard0748  \n",
      "Competitive Profiles:  \n",
      "- LeetCode: https://leetcode.co...\n"
     ]
    }
   ],
   "source": [
    "# Split document into chunks\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "print(\"Splitting document into chunks...\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_text(document_text)\n",
    "\n",
    "print(f\"‚úì Document split into {len(chunks)} chunks\")\n",
    "print(f\"‚úì Average chunk size: {len(document_text) // len(chunks) if chunks else 0} characters\")\n",
    "print(f\"\\nFirst chunk preview:\\n{chunks[0][:300]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "697abc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating vector store...\n",
      "‚úì Vector store created successfully\n",
      "‚úì Vector store type: FAISS\n",
      "‚úì Number of vectors: 65\n",
      "‚úì Retriever initialized (returns top 3 matches)\n"
     ]
    }
   ],
   "source": [
    "# Create vector store from chunks\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "print(\"\\nCreating vector store...\")\n",
    "\n",
    "# Convert chunks to Document objects\n",
    "documents = [Document(page_content=chunk) for chunk in chunks]\n",
    "\n",
    "# Create FAISS vector store\n",
    "vector_store = FAISS.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "print(\"‚úì Vector store created successfully\")\n",
    "print(f\"‚úì Vector store type: FAISS\")\n",
    "print(f\"‚úì Number of vectors: {vector_store.index.ntotal if hasattr(vector_store.index, 'ntotal') else len(documents)}\")\n",
    "\n",
    "# Create retriever\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "print(\"‚úì Retriever initialized (returns top 3 matches)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac510af9",
   "metadata": {},
   "source": [
    "## Section 5: Create Validation Agent\n",
    "\n",
    "This agent validates whether a question is appropriate to share with HR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "169d1b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Validation agent created successfully\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Dict, Any\n",
    "\n",
    "# Define validation response structure\n",
    "class ValidationResponse(BaseModel):\n",
    "    is_hr_appropriate: bool = Field(description=\"Whether the question is appropriate for HR\")\n",
    "    confidence: float = Field(description=\"Confidence score 0-1\")\n",
    "    reason: str = Field(description=\"Reason for validation decision\")\n",
    "    category: str = Field(description=\"Category of the question\")\n",
    "\n",
    "# Create validation agent\n",
    "validation_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an HR-appropriate question validator for Ravikumar's personal data system.\n",
    "    \n",
    "Your task is to validate if the following question is appropriate to answer using Ravikumar's personal data in an HR context.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Consider:\n",
    "1. Is the question professional and HR-relevant?\n",
    "2. Does it ask about work experience, skills, education, or professional achievements?\n",
    "3. Does it respect privacy and professional boundaries?\n",
    "4. Is it suitable for HR department discussion?\n",
    "\n",
    "Respond with a JSON object containing:\n",
    "- is_hr_appropriate: boolean\n",
    "- confidence: float (0-1)\n",
    "- reason: brief explanation\n",
    "- category: \"professional\", \"personal\", \"inappropriate\", or \"other\"\n",
    "\n",
    "Example response format:\n",
    "{{\"is_hr_appropriate\": true, \"confidence\": 0.95, \"reason\": \"Asks about work experience\", \"category\": \"professional\"}}\n",
    "\n",
    "Your validation response:\"\"\"\n",
    ")\n",
    "\n",
    "def validate_question(question: str) -> Dict[str, Any]:\n",
    "    \"\"\"Validate if a question is appropriate for HR\"\"\"\n",
    "    print(f\"\\nüîç Validating question: '{question}'\")\n",
    "    \n",
    "    # Generate validation\n",
    "    validation_chain = validation_prompt | llm\n",
    "    response = validation_chain.invoke({\"question\": question})\n",
    "    \n",
    "    # Parse response\n",
    "    import json\n",
    "    try:\n",
    "        response_text = response.content\n",
    "        # Extract JSON from response\n",
    "        json_start = response_text.find('{')\n",
    "        json_end = response_text.rfind('}') + 1\n",
    "        if json_start != -1 and json_end > json_start:\n",
    "            json_str = response_text[json_start:json_end]\n",
    "            validation_result = json.loads(json_str)\n",
    "        else:\n",
    "            validation_result = {\n",
    "                \"is_hr_appropriate\": False,\n",
    "                \"confidence\": 0.5,\n",
    "                \"reason\": \"Could not parse validation response\",\n",
    "                \"category\": \"other\"\n",
    "            }\n",
    "    except json.JSONDecodeError:\n",
    "        validation_result = {\n",
    "            \"is_hr_appropriate\": False,\n",
    "            \"confidence\": 0.5,\n",
    "            \"reason\": \"Error parsing validation response\",\n",
    "            \"category\": \"other\"\n",
    "        }\n",
    "    \n",
    "    return validation_result\n",
    "\n",
    "print(\"‚úì Validation agent created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20114e6",
   "metadata": {},
   "source": [
    "## Section 6: Create RAG Retrieval Agent\n",
    "\n",
    "This agent retrieves relevant information from Ravikumar's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e10ed8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì RAG retrieval agent created successfully\n"
     ]
    }
   ],
   "source": [
    "# Create RAG retrieval agent\n",
    "rag_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"You are Ravikumar's HR information assistant. Using the provided personal data, answer the HR's question accurately and professionally.\n",
    "\n",
    "Context from Ravikumar's records:\n",
    "{context}\n",
    "\n",
    "HR's Question: {question}\n",
    "\n",
    "Instructions:\n",
    "1. Answer based ONLY on the provided context\n",
    "2. Be professional and concise\n",
    "3. If information is not in the context, clearly state \"This information is not available in the records\"\n",
    "4. Cite specific sections when relevant\n",
    "5. Maintain confidentiality and professionalism\n",
    "\n",
    "Your response:\"\"\"\n",
    ")\n",
    "\n",
    "def retrieve_and_answer(question: str, validation_result: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Retrieve information and generate answer\"\"\"\n",
    "    \n",
    "    if not validation_result.get(\"is_hr_appropriate\"):\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"answer\": \"‚ùå This question is not appropriate to discuss with HR based on our guidelines.\",\n",
    "            \"reason\": validation_result.get(\"reason\"),\n",
    "            \"context_retrieved\": []\n",
    "        }\n",
    "    \n",
    "    print(f\"\\nüìö Retrieving relevant information...\")\n",
    "    \n",
    "    # Retrieve relevant documents\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "    \n",
    "    print(f\"‚úì Retrieved {len(retrieved_docs)} relevant documents\")\n",
    "    \n",
    "    # Generate answer\n",
    "    rag_chain = rag_prompt | llm\n",
    "    response = rag_chain.invoke({\n",
    "        \"context\": context,\n",
    "        \"question\": question\n",
    "    })\n",
    "    \n",
    "    return {\n",
    "        \"success\": True,\n",
    "        \"answer\": response.content,\n",
    "        \"reason\": validation_result.get(\"reason\"),\n",
    "        \"context_retrieved\": [doc.page_content[:200] + \"...\" for doc in retrieved_docs]\n",
    "    }\n",
    "\n",
    "print(\"‚úì RAG retrieval agent created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9a50eb",
   "metadata": {},
   "source": [
    "## Section 7: Set Up Multi-Agent Orchestrator\n",
    "\n",
    "This orchestrator coordinates all agents and handles query routing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e21748d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Multi-Agent Orchestrator initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# Multi-Agent Orchestrator\n",
    "class MultiAgentOrchestrator:\n",
    "    \"\"\"Orchestrates multiple agents to handle HR queries about Ravikumar's data\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str = \"Ravikumar HR Assistant\"):\n",
    "        self.name = name\n",
    "        self.query_history = []\n",
    "        self.agent_logs = []\n",
    "    \n",
    "    def process_query(self, question: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Process a query through the multi-agent system:\n",
    "        1. Validate the question\n",
    "        2. Retrieve relevant information\n",
    "        3. Generate response\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"ü§ñ {self.name} - Processing Query\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Step 1: Validate the question\n",
    "        print(\"\\n[Step 1/3] VALIDATION AGENT\")\n",
    "        print(\"-\" * 40)\n",
    "        validation_result = validate_question(question)\n",
    "        \n",
    "        print(f\"‚úì Is HR Appropriate: {validation_result['is_hr_appropriate']}\")\n",
    "        print(f\"‚úì Confidence: {validation_result['confidence']:.2%}\")\n",
    "        print(f\"‚úì Category: {validation_result['category']}\")\n",
    "        print(f\"‚úì Reason: {validation_result['reason']}\")\n",
    "        \n",
    "        # Step 2: Retrieve and answer (if validated)\n",
    "        print(\"\\n[Step 2/3] RAG RETRIEVAL AGENT\")\n",
    "        print(\"-\" * 40)\n",
    "        rag_result = retrieve_and_answer(question, validation_result)\n",
    "        \n",
    "        # Step 3: Generate final response\n",
    "        print(\"\\n[Step 3/3] FINAL RESPONSE\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        final_response = {\n",
    "            \"query\": question,\n",
    "            \"validation\": validation_result,\n",
    "            \"retrieval\": rag_result,\n",
    "            \"success\": rag_result[\"success\"],\n",
    "            \"timestamp\": __import__('datetime').datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        self.query_history.append(final_response)\n",
    "        \n",
    "        # Display answer\n",
    "        print(f\"\\nüìù Answer:\\n{rag_result['answer']}\")\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        \n",
    "        return final_response\n",
    "    \n",
    "    def get_history(self) -> list:\n",
    "        \"\"\"Get query history\"\"\"\n",
    "        return self.query_history\n",
    "    \n",
    "    def print_summary(self):\n",
    "        \"\"\"Print summary of all queries\"\"\"\n",
    "        print(f\"\\nüìä Summary Report - {len(self.query_history)} queries processed\")\n",
    "        for i, query in enumerate(self.query_history, 1):\n",
    "            print(f\"\\n{i}. Query: {query['query']}\")\n",
    "            print(f\"   Validated: {query['validation']['is_hr_appropriate']}\")\n",
    "            print(f\"   Success: {query['success']}\")\n",
    "\n",
    "# Initialize orchestrator\n",
    "orchestrator = MultiAgentOrchestrator()\n",
    "print(\"‚úì Multi-Agent Orchestrator initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b227c2",
   "metadata": {},
   "source": [
    "## Section 8: Test the Multi-Agent System\n",
    "\n",
    "Test with sample HR queries to demonstrate the complete workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "350df750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ü§ñ Ravikumar HR Assistant - Processing Query\n",
      "================================================================================\n",
      "\n",
      "[Step 1/3] VALIDATION AGENT\n",
      "----------------------------------------\n",
      "\n",
      "üîç Validating question: 'Can you tell me about Ravikumar's work experience and professional background?'\n",
      "‚úì Is HR Appropriate: True\n",
      "‚úì Confidence: 98.00%\n",
      "‚úì Category: professional\n",
      "‚úì Reason: Asks about work experience and professional background, which is relevant to HR context.\n",
      "\n",
      "[Step 2/3] RAG RETRIEVAL AGENT\n",
      "----------------------------------------\n",
      "\n",
      "üìö Retrieving relevant information...\n",
      "‚úì Retrieved 3 relevant documents\n",
      "\n",
      "[Step 3/3] FINAL RESPONSE\n",
      "----------------------------------------\n",
      "\n",
      "üìù Answer:\n",
      "I have reviewed Ravikumar D's personal profile and provided information. \n",
      "\n",
      "Ravikumar D is an aspiring Machine Learning Engineer with a strong academic background in Computer Science and Engineering with a specialization in Artificial Intelligence and Machine Learning.\n",
      "\n",
      "Regarding his work experience, Ravikumar has completed an internship at Lysa Solution in May 2025, where he gained hands-on experience in integrating Large Language Models (LLMs) into workflows. (Refer to INTERNSHIPS section)\n",
      "\n",
      "As per the provided context, Ravikumar is currently pursuing his B.E. in Computer Science and Engineering with a specialization in Artificial Intelligence and Machine Learning at Sri Eshwar College of Engineering, Coimbatore. (Refer to EDUCATION section)\n",
      "\n",
      "Please note that this information is based solely on the provided context and may not be comprehensive. If you require any further information, please let me know.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test Query 1: Professional/HR-Appropriate\n",
    "query_1 = \"Can you tell me about Ravikumar's work experience and professional background?\"\n",
    "result_1 = orchestrator.process_query(query_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "791ad0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ü§ñ Ravikumar HR Assistant - Processing Query\n",
      "================================================================================\n",
      "\n",
      "[Step 1/3] VALIDATION AGENT\n",
      "----------------------------------------\n",
      "\n",
      "üîç Validating question: 'What are Ravikumar's technical skills and expertise?'\n",
      "‚úì Is HR Appropriate: True\n",
      "‚úì Confidence: 98.00%\n",
      "‚úì Category: professional\n",
      "‚úì Reason: Asks about technical skills and expertise, which is relevant to work performance and professional development.\n",
      "\n",
      "[Step 2/3] RAG RETRIEVAL AGENT\n",
      "----------------------------------------\n",
      "\n",
      "üìö Retrieving relevant information...\n",
      "‚úì Retrieved 3 relevant documents\n",
      "\n",
      "[Step 3/3] FINAL RESPONSE\n",
      "----------------------------------------\n",
      "\n",
      "üìù Answer:\n",
      "Based on Ravikumar's personal profile and summary, I can provide the following information on his technical skills and expertise:\n",
      "\n",
      "Ravikumar is an aspiring Machine Learning Engineer with expertise in Artificial Intelligence and Machine Learning. His technical skills and expertise include:\n",
      "\n",
      "- Programming skills: Although not explicitly mentioned, his involvement in various coding platforms (e.g., LeetCode, CodeChef, HackerRank, and GitHub) suggests proficiency in programming languages such as Python, Java, or C++.\n",
      "- Machine Learning: His specialization in Artificial Intelligence and Machine Learning (AIML) and experience in integrating Large Language Models (LLMs) into workflows (as mentioned in the internship section) indicate his expertise in Machine Learning.\n",
      "- Large Language Models (LLMs): His hands-on experience in integrating LLMs into workflows (AI/ML Internship ‚Äì Lysa Solution, May 2025) demonstrates his understanding of LLMs.\n",
      "- Competitive programming: His participation in various coding platforms (LeetCode, CodeChef, HackerRank, and HackerEarth) showcases his competitive programming skills.\n",
      "\n",
      "Please note that the specific programming languages and technologies used by Ravikumar are not explicitly mentioned in the provided context.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test Query 2: Technical Skills\n",
    "query_2 = \"What are Ravikumar's technical skills and expertise?\"\n",
    "result_2 = orchestrator.process_query(query_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34bbbe68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ü§ñ Ravikumar HR Assistant - Processing Query\n",
      "================================================================================\n",
      "\n",
      "[Step 1/3] VALIDATION AGENT\n",
      "----------------------------------------\n",
      "\n",
      "üîç Validating question: 'What is Ravikumar's educational background?'\n",
      "‚úì Is HR Appropriate: True\n",
      "‚úì Confidence: 90.00%\n",
      "‚úì Category: professional\n",
      "‚úì Reason: Asks about educational background, which is relevant to HR for employee onboarding, training, and career development purposes.\n",
      "\n",
      "[Step 2/3] RAG RETRIEVAL AGENT\n",
      "----------------------------------------\n",
      "\n",
      "üìö Retrieving relevant information...\n",
      "‚úì Retrieved 3 relevant documents\n",
      "\n",
      "[Step 3/3] FINAL RESPONSE\n",
      "----------------------------------------\n",
      "\n",
      "üìù Answer:\n",
      "Based on the provided personal data, Ravikumar's educational background is as follows:\n",
      "\n",
      "Ravikumar is currently pursuing his B.E. in Computer Science and Engineering with a specialization in Artificial Intelligence and Machine Learning at Sri Eshwar College of Engineering, Coimbatore. \n",
      "\n",
      "Specifically, the records indicate that he is in his 4th semester (PERSONAL PROFILE, EDUCATION). Additionally, prior to his B.E. program, he completed his Higher Secondary School (HSC) at The Merit Higher Secondary School with a score of 90.6% (EDUCATION) and his Secondary School Leaving Certificate (SSLC) at The Merit Higher Secondary School (EDUCATION).\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test Query 3: Education\n",
    "query_3 = \"What is Ravikumar's educational background?\"\n",
    "result_3 = orchestrator.process_query(query_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a802017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ü§ñ Ravikumar HR Assistant - Processing Query\n",
      "================================================================================\n",
      "\n",
      "[Step 1/3] VALIDATION AGENT\n",
      "----------------------------------------\n",
      "\n",
      "üîç Validating question: 'What certifications and achievements does Ravikumar have?'\n",
      "‚úì Is HR Appropriate: True\n",
      "‚úì Confidence: 98.00%\n",
      "‚úì Category: professional\n",
      "‚úì Reason: Asks about professional achievements and certifications, relevant to work experience and skills.\n",
      "\n",
      "[Step 2/3] RAG RETRIEVAL AGENT\n",
      "----------------------------------------\n",
      "\n",
      "üìö Retrieving relevant information...\n",
      "‚úì Retrieved 3 relevant documents\n",
      "\n",
      "[Step 3/3] FINAL RESPONSE\n",
      "----------------------------------------\n",
      "\n",
      "üìù Answer:\n",
      "Based on Ravikumar's records, I have found the following certifications and achievements:\n",
      "\n",
      "- CGPA: 8.09 in B.E. (CSE-AIML) at Sri Eshwar College of Engineering (PERSONAL PROFILE, EDUCATION)\n",
      "- Scored 90.6% in HSC (Class 12) at The Merit Higher Secondary School (PERSONAL PROFILE, EDUCATION)\n",
      "- Passed in SSLC (Class 10) at The Merit Higher Secondary School (PERSONAL PROFILE, EDUCATION)\n",
      "\n",
      "Additionally, Ravikumar has completed an internship at Lysa Solution in May 2025, where he gained hands-on experience in integrating Large Language Models (LLMs) into workflows (PERSONAL PROFILE, INTERNSHIPS).\n",
      "\n",
      "This information is not available in the records regarding specific certifications, such as industry-recognized certifications or professional licenses.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test Query 4: Certifications\n",
    "query_4 = \"What certifications and achievements does Ravikumar have?\"\n",
    "result_4 = orchestrator.process_query(query_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06127079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ü§ñ Ravikumar HR Assistant - Processing Query\n",
      "================================================================================\n",
      "\n",
      "[Step 1/3] VALIDATION AGENT\n",
      "----------------------------------------\n",
      "\n",
      "üîç Validating question: 'What is Ravikumar's home address and personal phone number?'\n",
      "‚úì Is HR Appropriate: False\n",
      "‚úì Confidence: 80.00%\n",
      "‚úì Category: personal\n",
      "‚úì Reason: Asks about personal contact information, which is not typically relevant to HR discussions or professional settings.\n",
      "\n",
      "[Step 2/3] RAG RETRIEVAL AGENT\n",
      "----------------------------------------\n",
      "\n",
      "[Step 3/3] FINAL RESPONSE\n",
      "----------------------------------------\n",
      "\n",
      "üìù Answer:\n",
      "‚ùå This question is not appropriate to discuss with HR based on our guidelines.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test Query 5: Inappropriate query (test validation agent)\n",
    "query_5 = \"What is Ravikumar's home address and personal phone number?\"\n",
    "result_5 = orchestrator.process_query(query_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ada018",
   "metadata": {},
   "source": [
    "## Section 9: System Summary and Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27690a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìä MULTI-AGENT RAG SYSTEM - SUMMARY REPORT\n",
      "================================================================================\n",
      "\n",
      "‚úì System Configuration:\n",
      "  - LLM: Groq (mixtral-8x7b-32768)\n",
      "  - Embeddings: HuggingFace (all-MiniLM-L6-v2)\n",
      "  - Vector Store: FAISS\n",
      "  - Document: Ravi_Total.docx\n",
      "\n",
      "‚úì Document Statistics:\n",
      "  - Total characters: 24,414\n",
      "  - Total chunks: 65\n",
      "  - Average chunk size: 375 chars\n",
      "\n",
      "‚úì Agents Deployed:\n",
      "  - Validation Agent: HR-appropriateness filter\n",
      "  - Retrieval Agent: Information retrieval (RAG)\n",
      "  - Orchestrator: Multi-agent coordination\n",
      "\n",
      "‚úì Queries Processed: 5\n",
      "  - HR Appropriate: 4/5\n",
      "  - Successfully Answered: 4/5\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üìä Summary Report - 5 queries processed\n",
      "\n",
      "1. Query: Can you tell me about Ravikumar's work experience and professional background?\n",
      "   Validated: True\n",
      "   Success: True\n",
      "\n",
      "2. Query: What are Ravikumar's technical skills and expertise?\n",
      "   Validated: True\n",
      "   Success: True\n",
      "\n",
      "3. Query: What is Ravikumar's educational background?\n",
      "   Validated: True\n",
      "   Success: True\n",
      "\n",
      "4. Query: What certifications and achievements does Ravikumar have?\n",
      "   Validated: True\n",
      "   Success: True\n",
      "\n",
      "5. Query: What is Ravikumar's home address and personal phone number?\n",
      "   Validated: False\n",
      "   Success: False\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Multi-Agent RAG System Ready for Deployment!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Print system summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä MULTI-AGENT RAG SYSTEM - SUMMARY REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n‚úì System Configuration:\")\n",
    "print(f\"  - LLM: Groq (mixtral-8x7b-32768)\")\n",
    "print(f\"  - Embeddings: HuggingFace (all-MiniLM-L6-v2)\")\n",
    "print(f\"  - Vector Store: FAISS\")\n",
    "print(f\"  - Document: Ravi_Total.docx\")\n",
    "\n",
    "print(f\"\\n‚úì Document Statistics:\")\n",
    "print(f\"  - Total characters: {len(document_text):,}\")\n",
    "print(f\"  - Total chunks: {len(chunks)}\")\n",
    "print(f\"  - Average chunk size: {len(document_text) // len(chunks) if chunks else 0} chars\")\n",
    "\n",
    "print(f\"\\n‚úì Agents Deployed:\")\n",
    "print(f\"  - Validation Agent: HR-appropriateness filter\")\n",
    "print(f\"  - Retrieval Agent: Information retrieval (RAG)\")\n",
    "print(f\"  - Orchestrator: Multi-agent coordination\")\n",
    "\n",
    "print(f\"\\n‚úì Queries Processed: {len(orchestrator.query_history)}\")\n",
    "\n",
    "# Statistics\n",
    "hr_appropriate_count = sum(1 for q in orchestrator.query_history if q['validation']['is_hr_appropriate'])\n",
    "successful_count = sum(1 for q in orchestrator.query_history if q['success'])\n",
    "\n",
    "print(f\"  - HR Appropriate: {hr_appropriate_count}/{len(orchestrator.query_history)}\")\n",
    "print(f\"  - Successfully Answered: {successful_count}/{len(orchestrator.query_history)}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Display individual query summary\n",
    "orchestrator.print_summary()\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ Multi-Agent RAG System Ready for Deployment!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09dffe9",
   "metadata": {},
   "source": [
    "## Section 10: Custom Query Interface\n",
    "\n",
    "Use this section to ask custom HR questions about Ravikumar's profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e198b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Custom Query Interface Ready!\n",
      "\n",
      "Usage: result = ask_ravikumar_system('Your question here')\n",
      "\n",
      "Example questions to try:\n",
      "  1. 'Can you tell me about Ravikumar's key achievements?'\n",
      "  2. 'What programming languages does Ravikumar know?'\n",
      "  3. 'How many years of experience does Ravikumar have?'\n",
      "  4. 'What are Ravikumar's certifications?'\n",
      "\n",
      "You can ask any professional/HR-related question!\n"
     ]
    }
   ],
   "source": [
    "# Custom query function for HR\n",
    "def ask_ravikumar_system(question: str):\n",
    "    \"\"\"\n",
    "    Ask the multi-agent RAG system about Ravikumar's professional profile.\n",
    "    \n",
    "    Args:\n",
    "        question: Your HR question about Ravikumar\n",
    "    \"\"\"\n",
    "    return orchestrator.process_query(question)\n",
    "\n",
    "# Example usage:\n",
    "# result = ask_ravikumar_system(\"What are Ravikumar's key achievements?\")\n",
    "\n",
    "print(\"\\n‚úÖ Custom Query Interface Ready!\")\n",
    "print(\"\\nUsage: result = ask_ravikumar_system('Your question here')\")\n",
    "print(\"\\nExample questions to try:\")\n",
    "print(\"  1. 'Can you tell me about Ravikumar's key achievements?'\")\n",
    "print(\"  2. 'What programming languages does Ravikumar know?'\")\n",
    "print(\"  3. 'How many years of experience does Ravikumar have?'\")\n",
    "print(\"  4. 'What are Ravikumar's certifications?'\")\n",
    "print(\"\\nYou can ask any professional/HR-related question!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
